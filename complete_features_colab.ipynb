{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Live-Cam Complete Features (No Live/NSFW)\n",
    "All features except live streaming and content filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!apt update -qq && apt install -y ffmpeg\n",
    "!git clone https://github.com/Mayank-kanojiya/liveswap.git\n",
    "%cd liveswap\n",
    "!pip install -q opencv-python onnxruntime-gpu torch torchvision insightface\n",
    "!pip install -q customtkinter pillow psutil protobuf cv2-enumerate-cameras\n",
    "!pip install -q git+https://github.com/xinntao/BasicSR.git@master\n",
    "!pip install -q git+https://github.com/TencentARC/GFPGAN.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download models\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "!wget -q -O models/GFPGANv1.4.pth https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth\n",
    "!wget -q -O models/inswapper_128_fp16.onnx https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Deep-Live-Cam Features\n",
    "import gradio as gr\n",
    "import cv2\n",
    "import tempfile\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "sys.path.append('.')\n",
    "\n",
    "import modules.globals\n",
    "modules.globals.headless = True\n",
    "modules.globals.execution_providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "\n",
    "from modules.processors.frame.face_swapper import get_face_swapper, process_frame\n",
    "from modules.face_analyser import get_one_face, get_many_faces\n",
    "from modules.utilities import is_video, extract_frames, create_video, restore_audio, get_temp_frame_paths, create_temp, clean_temp, detect_fps\n",
    "\n",
    "face_swapper = get_face_swapper()\n",
    "\n",
    "def advanced_face_swap(source_image, target_media, \n",
    "                      mouth_mask=False, many_faces=False, map_faces=False,\n",
    "                      keep_fps=True, keep_audio=True, face_enhancer=False,\n",
    "                      video_encoder='libx264', video_quality=18):\n",
    "    \n",
    "    if source_image is None or target_media is None:\n",
    "        return None, \"Upload both source and target files\"\n",
    "    \n",
    "    try:\n",
    "        # Set global options\n",
    "        modules.globals.mouth_mask = mouth_mask\n",
    "        modules.globals.many_faces = many_faces\n",
    "        modules.globals.map_faces = map_faces\n",
    "        modules.globals.keep_fps = keep_fps\n",
    "        modules.globals.keep_audio = keep_audio\n",
    "        modules.globals.video_encoder = video_encoder\n",
    "        modules.globals.video_quality = video_quality\n",
    "        \n",
    "        # Frame processors\n",
    "        processors = ['face_swapper']\n",
    "        if face_enhancer:\n",
    "            processors.append('face_enhancer')\n",
    "        modules.globals.frame_processors = processors\n",
    "        \n",
    "        modules.globals.source_path = source_image\n",
    "        modules.globals.target_path = target_media.name\n",
    "        \n",
    "        source_img = cv2.imread(source_image)\n",
    "        source_face = get_one_face(source_img)\n",
    "        \n",
    "        if source_face is None:\n",
    "            return None, \"No face detected in source image\"\n",
    "        \n",
    "        if is_video(target_media.name):\n",
    "            # Video processing\n",
    "            output_path = tempfile.mktemp(suffix='.mp4')\n",
    "            modules.globals.output_path = output_path\n",
    "            \n",
    "            print(\"Processing video with advanced features...\")\n",
    "            create_temp(target_media.name)\n",
    "            extract_frames(target_media.name)\n",
    "            \n",
    "            temp_frame_paths = get_temp_frame_paths(target_media.name)\n",
    "            \n",
    "            for i, frame_path in enumerate(temp_frame_paths):\n",
    "                frame = cv2.imread(frame_path)\n",
    "                \n",
    "                if many_faces:\n",
    "                    target_faces = get_many_faces(frame)\n",
    "                    for target_face in target_faces:\n",
    "                        result_frame = process_frame(source_face, frame)\n",
    "                else:\n",
    "                    result_frame = process_frame(source_face, frame)\n",
    "                \n",
    "                cv2.imwrite(frame_path, result_frame)\n",
    "                \n",
    "                if i % 30 == 0:\n",
    "                    print(f\"Processed {i+1}/{len(temp_frame_paths)} frames\")\n",
    "            \n",
    "            # Create video with options\n",
    "            if keep_fps:\n",
    "                fps = detect_fps(target_media.name)\n",
    "                create_video(target_media.name, fps)\n",
    "            else:\n",
    "                create_video(target_media.name)\n",
    "            \n",
    "            # Handle audio\n",
    "            if keep_audio:\n",
    "                restore_audio(target_media.name, output_path)\n",
    "            else:\n",
    "                # Move without audio\n",
    "                temp_video = f\"/tmp/{os.path.basename(target_media.name)}\"\n",
    "                if os.path.exists(temp_video):\n",
    "                    shutil.move(temp_video, output_path)\n",
    "            \n",
    "            clean_temp(target_media.name)\n",
    "            \n",
    "            return output_path, f\"Video processed with {video_encoder} encoder, quality {video_quality}\"\n",
    "            \n",
    "        else:\n",
    "            # Image processing\n",
    "            output_path = tempfile.mktemp(suffix='.jpg')\n",
    "            target_img = cv2.imread(target_media.name)\n",
    "            \n",
    "            if many_faces:\n",
    "                target_faces = get_many_faces(target_img)\n",
    "                for target_face in target_faces:\n",
    "                    result_frame = process_frame(source_face, target_img)\n",
    "            else:\n",
    "                result_frame = process_frame(source_face, target_img)\n",
    "            \n",
    "            cv2.imwrite(output_path, result_frame)\n",
    "            \n",
    "            return output_path, \"Image face swap completed!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"Complete Deep-Live-Cam features loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Gradio Interface\n",
    "with gr.Blocks(title=\"Deep-Live-Cam Complete\") as demo:\n",
    "    gr.Markdown(\"# Deep-Live-Cam - Complete Features\")\n",
    "    gr.Markdown(\"All original features except live streaming and content filters\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            source_image = gr.Image(label=\"Source Face Image\", type=\"filepath\")\n",
    "            target_media = gr.File(label=\"Target Image/Video\")\n",
    "            \n",
    "            # Face Processing Options\n",
    "            with gr.Group():\n",
    "                gr.Markdown(\"### Face Processing\")\n",
    "                mouth_mask = gr.Checkbox(label=\"Mouth Mask (preserve eating/talking)\", value=False)\n",
    "                many_faces = gr.Checkbox(label=\"Process All Faces\", value=False)\n",
    "                map_faces = gr.Checkbox(label=\"Map Source to Target Faces\", value=False)\n",
    "                face_enhancer = gr.Checkbox(label=\"Face Enhancement (GFPGAN)\", value=False)\n",
    "            \n",
    "            # Video Options\n",
    "            with gr.Group():\n",
    "                gr.Markdown(\"### Video Options\")\n",
    "                keep_fps = gr.Checkbox(label=\"Keep Original FPS\", value=True)\n",
    "                keep_audio = gr.Checkbox(label=\"Keep Original Audio\", value=True)\n",
    "                video_encoder = gr.Dropdown(\n",
    "                    choices=['libx264', 'libx265', 'libvpx-vp9'],\n",
    "                    value='libx264',\n",
    "                    label=\"Video Encoder\"\n",
    "                )\n",
    "                video_quality = gr.Slider(\n",
    "                    minimum=0, maximum=51, value=18,\n",
    "                    label=\"Video Quality (0=best, 51=worst)\"\n",
    "                )\n",
    "            \n",
    "            process_btn = gr.Button(\"Process Face Swap\", variant=\"primary\")\n",
    "            \n",
    "        with gr.Column():\n",
    "            result_media = gr.File(label=\"Result\")\n",
    "            status_text = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            \n",
    "            # GPU Info\n",
    "            with gr.Group():\n",
    "                gr.Markdown(\"### GPU Acceleration\")\n",
    "                gpu_info = gr.Textbox(label=\"GPU Status\", interactive=False)\n",
    "    \n",
    "    # Check GPU on load\n",
    "    def check_gpu():\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            return f\"✅ GPU: {torch.cuda.get_device_name(0)}\"\n",
    "        else:\n",
    "            return \"❌ CPU Only\"\n",
    "    \n",
    "    demo.load(check_gpu, outputs=gpu_info)\n",
    "    \n",
    "    process_btn.click(\n",
    "        fn=advanced_face_swap,\n",
    "        inputs=[\n",
    "            source_image, target_media,\n",
    "            mouth_mask, many_faces, map_faces,\n",
    "            keep_fps, keep_audio, face_enhancer,\n",
    "            video_encoder, video_quality\n",
    "        ],\n",
    "        outputs=[result_media, status_text]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "name": "python",\n   "version": "3.8.10"\n  },\n  "accelerator": "GPU"\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}